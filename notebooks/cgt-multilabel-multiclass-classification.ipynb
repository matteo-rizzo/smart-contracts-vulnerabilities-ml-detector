{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import",
   "id": "172880abc3d187d8"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-13T10:01:47.042533Z",
     "start_time": "2024-07-13T10:01:47.035078Z"
    }
   },
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "from collections import Counter\n",
    "from typing import Tuple, Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "from torch.utils.data import RandomSampler\n",
    "from tqdm import tqdm\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.warn = warn"
   ],
   "outputs": [],
   "execution_count": 102
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Configuration",
   "id": "fc1ec8b396d0a08e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T09:57:45.348776Z",
     "start_time": "2024-07-13T09:57:45.339596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on device {DEVICE}\")\n",
    "\n",
    "RANDOM_SEED = 0\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "LOG_DIR = os.path.join(\"log\")\n",
    "if not os.path.exists(LOG_DIR):\n",
    "    os.makedirs(LOG_DIR)\n",
    "\n",
    "PATH_TO_DATASET = os.path.join(\"..\", \"dataset\", \"cgt\")\n",
    "BERT_MODEL_TYPE = 'microsoft/codebert-base'\n",
    "\n",
    "MAX_FEATURES = 500\n",
    "BATCH_SIZE = 2\n",
    "NUM_FOLDS = 2\n",
    "NUM_EPOCHS = 1\n",
    "NUM_LABELS = 20\n",
    "LR = 0.001\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "FILE_TYPE = \"runtime\"\n",
    "FILE_EXT = \".rt.hex\"\n",
    "FILE_ID = \"runtime\""
   ],
   "id": "1374f63db7c6cea9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device cpu\n"
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Dataset\n",
    "\n",
    "Create PyTorch dataset feeding either source code, bytecode or runtime to the models."
   ],
   "id": "a424b60aff524ded"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing",
   "id": "24ae2bd4455509d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T09:57:47.414271Z",
     "start_time": "2024-07-13T09:57:47.412022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_hex(hex_data: str) -> str:\n",
    "    # Reads a hex file and converts it to a byte string\n",
    "    byte_data = bytes.fromhex(hex_data.strip())\n",
    "\n",
    "    # Convert byte data to a readable ASCII string, ignoring non-ASCII characters\n",
    "    return ' '.join(f'{byte:02x}' for byte in byte_data)"
   ],
   "id": "41e2ed4561254c43",
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T09:57:47.821374Z",
     "start_time": "2024-07-13T09:57:47.818445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_solidity_code(code: str) -> str:\n",
    "    # Remove single-line comments\n",
    "    code = re.sub(r'//.*', '', code)\n",
    "\n",
    "    # Remove multi-line comments\n",
    "    code = re.sub(r'/\\*.*?\\*/', '', code, flags=re.DOTALL)\n",
    "\n",
    "    # Remove blank lines (lines only containing whitespace)\n",
    "    lines = code.split('\\n')\n",
    "    non_blank_lines = [line for line in lines if line.strip() != '']\n",
    "    code = '\\n'.join(non_blank_lines)\n",
    "\n",
    "    return code"
   ],
   "id": "f75a48b51037e77c",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T09:57:48.100053Z",
     "start_time": "2024-07-13T09:57:48.097272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess(data: str):\n",
    "    return preprocess_solidity_code(data) if FILE_TYPE == \"source\" else preprocess_hex(data)"
   ],
   "id": "15fa061be57e6304",
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Labels Management",
   "id": "7e084d9053915673"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T09:57:48.757200Z",
     "start_time": "2024-07-13T09:57:48.751168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def init_docs_and_gt(data: pd.DataFrame, file_type: str = FILE_TYPE, file_ext: str = FILE_EXT) -> Tuple:\n",
    "    docs, labels, gt = {}, {}, {}\n",
    "    for _, row in tqdm(data.iterrows(), desc=\"Initializing documents and groundtruth data\"):\n",
    "        item_id, file_id = row[\"id\"], row[\"fp_\" + FILE_ID]\n",
    "\n",
    "        # Check if file exists\n",
    "        path_to_file = os.path.join(PATH_TO_DATASET, file_type, str(file_id) + file_ext)\n",
    "        if os.path.exists(path_to_file):\n",
    "\n",
    "            # Initialize the documents\n",
    "            docs[item_id] = preprocess(open(path_to_file, 'r', encoding=\"utf8\").read())\n",
    "\n",
    "            # Initialize the label\n",
    "            labels[item_id] = [0] * NUM_LABELS\n",
    "\n",
    "            # Initialize the groundtruth\n",
    "            prop = row[\"property\"].lower()\n",
    "            if prop not in gt.keys():\n",
    "                gt[prop] = len(gt.values())\n",
    "\n",
    "    return list(docs.values()), labels, gt"
   ],
   "id": "1511840b0951d215",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T09:57:49.239464Z",
     "start_time": "2024-07-13T09:57:49.235845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def set_labels(data: pd.DataFrame, labels: Dict, gt: Dict, file_type: str = FILE_TYPE,\n",
    "               file_ext: str = FILE_EXT) -> List:\n",
    "    for _, row in tqdm(data.iterrows(), desc=\"Setting up the labels\"):\n",
    "        item_id, file_id = row[\"id\"], row[\"fp_\" + FILE_ID]\n",
    "\n",
    "        # Check if file exists\n",
    "        path_to_file = os.path.join(PATH_TO_DATASET, file_type, str(file_id) + file_ext)\n",
    "        if os.path.exists(path_to_file):\n",
    "\n",
    "            # Set label   \n",
    "            prop = row[\"property\"].lower()\n",
    "            if row['property_holds'] == 't':\n",
    "                labels[item_id][gt[prop]] = 1\n",
    "\n",
    "    return list(labels.values())"
   ],
   "id": "89cc44af1e668270",
   "outputs": [],
   "execution_count": 95
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initialization of the dataset",
   "id": "bac1ca9644eca1a4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T09:57:57.487867Z",
     "start_time": "2024-07-13T09:57:50.209666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read the dataset from CSV\n",
    "dataset = pd.read_csv(os.path.join(PATH_TO_DATASET, \"consolidated.csv\"), sep=\";\")\n",
    "\n",
    "# Count the frequency of each item in the column\n",
    "frequency = dataset['dataset'].value_counts()\n",
    "\n",
    "# Find the item with the maximum occurrence\n",
    "most_frequent_item = frequency.idxmax()\n",
    "most_frequent_count = frequency.max()\n",
    "\n",
    "print(f\"The most frequent item in the column is '{most_frequent_item}' and it appears {most_frequent_count} times.\")\n",
    "\n",
    "# Exclude outliers from the dataset\n",
    "dataset = dataset[dataset[\"dataset\"] == most_frequent_item]\n",
    "\n",
    "# Initialize the documents and the groundtruth\n",
    "documents, labels, gt = init_docs_and_gt(dataset)\n",
    "\n",
    "# Set the labels for the multilabel classification problem\n",
    "labels = set_labels(dataset, labels, gt)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=MAX_FEATURES)"
   ],
   "id": "fb254a69e43e824e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent item in the column is 'CodeSmells' and it appears 10395 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing documents and groundtruth data: 10395it [00:06, 1487.77it/s]\n",
      "Setting up the labels: 10395it [00:00, 47924.23it/s]\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Utility functions",
   "id": "546491e26d424c8b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T09:58:01.172957Z",
     "start_time": "2024-07-13T09:58:01.157655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_metrics(true_labels, pred_labels):\n",
    "    return {\n",
    "        \"precision\": precision_score(true_labels, pred_labels, average='samples', zero_division=0),\n",
    "        \"recall\": recall_score(true_labels, pred_labels, average='samples', zero_division=0),\n",
    "        \"f1\": f1_score(true_labels, pred_labels, average='samples', zero_division=0)\n",
    "    }\n",
    "\n",
    "\n",
    "def save_results(results, filename):\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(os.path.join(LOG_DIR, filename), index=False)\n",
    "    print(f\"All fold results saved to '{filename}'\")"
   ],
   "id": "543bd399383e5b7e",
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# BERT-like Models",
   "id": "f2934d41ac3e7b8f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T08:12:47.347301Z",
     "start_time": "2024-07-13T08:12:44.034032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(BERT_MODEL_TYPE, num_labels=20, ignore_mismatched_sizes=True)\n",
    "model.config.problem_type = \"multi_label_classification\"\n",
    "model.to(DEVICE)\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(BERT_MODEL_TYPE, ignore_mismatched_sizes=True)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LR)\n",
    "loss_fn = nn.BCEWithLogitsLoss()"
   ],
   "id": "5acdc46ff12870a3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T08:12:47.360858Z",
     "start_time": "2024-07-13T08:12:47.354640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_and_evaluate(model, train_dataloader, test_dataloader):\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f\"\\n --- Epoch {epoch + 1}/{NUM_EPOCHS} ---\")\n",
    "\n",
    "        # Training Phase\n",
    "        model.train()  # Set the model to training mode\n",
    "        train_losses, train_metrics_list = [], []\n",
    "\n",
    "        for batch in tqdm(train_dataloader, desc=\"Training\"):\n",
    "            batch = tuple(b.to(model.device) for b in batch)\n",
    "            inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
    "\n",
    "            model.zero_grad()  # Clear existing gradients\n",
    "            outputs = model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, inputs['labels'])\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()  # Compute gradient\n",
    "            optimizer.step()  # Update model parameters\n",
    "\n",
    "            with torch.no_grad():\n",
    "                predictions = torch.sigmoid(outputs.logits).round().cpu().numpy()\n",
    "                batch_metrics = compute_metrics(batch[2].cpu().numpy(), predictions)\n",
    "                train_metrics_list.append(batch_metrics)\n",
    "\n",
    "        avg_train_loss = np.mean(train_losses)\n",
    "        # Calculate average training metrics\n",
    "        avg_train_metrics = {metric: np.mean([m[metric] for m in train_metrics_list]) for metric in\n",
    "                             train_metrics_list[0]}\n",
    "        print(\n",
    "            f\"\\n TRAIN | Loss: {avg_train_loss:.4f} | Precision: {avg_train_metrics['precision']:.4f}, Recall: {avg_train_metrics['recall']:.4f}, F1: {avg_train_metrics['f1']:.4f}\\n\")\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        test_losses, test_metrics_list = [], []\n",
    "\n",
    "        for batch in tqdm(test_dataloader, desc=\"Testing\"):\n",
    "            batch = tuple(b.to(model.device) for b in batch)\n",
    "            inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "                loss = loss_fn(outputs.logits, inputs['labels'])\n",
    "                test_losses.append(loss.item())\n",
    "                predictions = torch.sigmoid(outputs.logits).round().cpu().numpy()\n",
    "                batch_metrics = compute_metrics(batch[2].cpu().numpy(), predictions)\n",
    "                test_metrics_list.append(batch_metrics)\n",
    "\n",
    "        avg_test_loss = np.mean(test_losses)\n",
    "        # Calculate average testing metrics\n",
    "        avg_test_metrics = {metric: np.mean([m[metric] for m in test_metrics_list]) for metric in test_metrics_list[0]}\n",
    "        print(\n",
    "            f\" VALID | Loss: {avg_test_loss:.4f} | Precision: {avg_test_metrics['precision']:.4f}, Recall: {avg_test_metrics['recall']:.4f}, F1: {avg_test_metrics['f1']:.4f}\\n\")"
   ],
   "id": "c80667693427c66a",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T08:12:47.365404Z",
     "start_time": "2024-07-13T08:12:47.361587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_on_test_set(model, test_dataloader):\n",
    "    # Put the model in evaluation mode which turns off specific layers like dropout\n",
    "    model.eval()\n",
    "\n",
    "    # Lists to store losses and metrics for each batch\n",
    "    test_losses, test_metrics = [], []\n",
    "\n",
    "    # Disable gradient calculations since we're only running inference, not training\n",
    "    with torch.no_grad():\n",
    "        # Iterate over batches in the provided DataLoader\n",
    "        for batch in tqdm(test_dataloader, desc=\"Evaluating on Test Set\"):\n",
    "            # Move the batch to the device (e.g., GPU) the model is on\n",
    "            batch = tuple(b.to(model.device) for b in batch)\n",
    "\n",
    "            # Prepare inputs dictionary according to the model's expected input\n",
    "            inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
    "\n",
    "            # Pass the inputs to the model and get outputs\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "            # Compute loss using the loss function defined outside this function\n",
    "            loss = loss_fn(outputs.logits, inputs['labels'])\n",
    "            test_losses.append(loss.item())\n",
    "\n",
    "            # Convert model logits to binary predictions\n",
    "            predictions = torch.sigmoid(outputs.logits).round().cpu().numpy()\n",
    "\n",
    "            # Compute metrics (e.g., precision, recall, F1) for the batch\n",
    "            batch_metrics = compute_metrics(batch[2].cpu().numpy(), predictions)\n",
    "            test_metrics.append(batch_metrics)\n",
    "\n",
    "    # Calculate the average loss over all batches\n",
    "    avg_test_loss = np.mean(test_losses)\n",
    "\n",
    "    # Calculate average metrics across all batches\n",
    "    avg_test_metrics = {metric: np.mean([m[metric] for m in test_metrics]) for metric in test_metrics[0]}\n",
    "\n",
    "    # Print out the average loss and other metrics for all batches\n",
    "    print(\n",
    "        f\"\\nTest Set Evaluation | Loss: {avg_test_loss:.4f} | Precision: {avg_test_metrics['precision']:.4f}, Recall: {avg_test_metrics['recall']:.4f}, F1: {avg_test_metrics['f1']:.4f}\\n\")\n",
    "\n",
    "    # Return a dictionary of average metrics\n",
    "    return avg_test_metrics\n"
   ],
   "id": "c2c756331f70649e",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T08:26:04.150469Z",
     "start_time": "2024-07-13T08:12:47.366011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tokenization\n",
    "encoding = tokenizer(documents, add_special_tokens=True, max_length=512,\n",
    "                     return_token_type_ids=False, padding=\"max_length\",\n",
    "                     truncation=True, return_attention_mask=True,\n",
    "                     return_tensors='pt')\n",
    "\n",
    "# Splitting data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(encoding['input_ids'], labels, test_size=TEST_SIZE)\n",
    "train_masks, test_masks, _, _ = train_test_split(encoding['attention_mask'], labels, test_size=TEST_SIZE)\n",
    "\n",
    "# Creating datasets\n",
    "train_dataset = TensorDataset(x_train, train_masks, torch.tensor(y_train).float())\n",
    "test_dataset = TensorDataset(x_test, test_masks, torch.tensor(y_test).float())\n",
    "\n",
    "# K-Fold Configuration\n",
    "kf = KFold(n_splits=NUM_FOLDS, shuffle=True)\n",
    "\n",
    "# Initialize a list to store metrics\n",
    "fold_metrics = []\n",
    "\n",
    "# Applying K-Fold Cross-Validation\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(train_dataset)):\n",
    "    train_subsampler = Subset(train_dataset, train_idx)\n",
    "    val_subsampler = Subset(train_dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_subsampler, sampler=RandomSampler(train_subsampler), batch_size=BATCH_SIZE)\n",
    "    val_loader = DataLoader(val_subsampler, batch_size=BATCH_SIZE)  # No need for shuffling\n",
    "\n",
    "    print(f\"Starting Fold {fold + 1}/{NUM_FOLDS}\")\n",
    "    train_and_evaluate(model, train_loader, val_loader)\n",
    "\n",
    "    # Evaluate on the test set after each fold\n",
    "    metrics = evaluate_on_test_set(model, DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False))\n",
    "    fold_metrics.append(metrics)\n",
    "\n",
    "# Save metrics to CSV\n",
    "df = pd.DataFrame(fold_metrics)\n",
    "df.to_csv(os.path.join(LOG_DIR, \"bert.csv\"), index=False)\n",
    "print(\"Metrics saved to bert.csv\")\n",
    "\n",
    "# Calculate average and standard deviation of each metric across all folds\n",
    "metric_keys = fold_metrics[0].keys()  # Assuming all metrics dictionaries have the same structure\n",
    "average_metrics = {key: np.mean([metric[key] for metric in fold_metrics]) for key in metric_keys}\n",
    "std_dev_metrics = {key: np.std([metric[key] for metric in fold_metrics]) for key in metric_keys}\n",
    "\n",
    "# Print average metrics and their standard deviations\n",
    "print(\"Average Metrics Over All Folds:\")\n",
    "for key, value in average_metrics.items():\n",
    "    print(f\"{key}: {value:.4f} (±{std_dev_metrics[key]:.4f})\")"
   ],
   "id": "cfb9656b31564534",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Fold 1/2\n",
      "\n",
      " --- Epoch 1/1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 110/110 [05:04<00:00,  2.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TRAIN | Loss: 0.3526 | Precision: 0.7370, Recall: 0.7016, F1: 0.6939\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 110/110 [00:52<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " VALID | Loss: 0.2513 | Precision: 0.8288, Recall: 0.7087, F1: 0.7404\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on Test Set: 100%|██████████| 56/56 [00:29<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Evaluation | Loss: 0.2715 | Precision: 0.8155, Recall: 0.6594, F1: 0.7044\n",
      "\n",
      "Starting Fold 2/2\n",
      "\n",
      " --- Epoch 1/1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 110/110 [05:34<00:00,  3.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TRAIN | Loss: 0.2691 | Precision: 0.7900, Recall: 0.7211, F1: 0.7247\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 110/110 [00:46<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " VALID | Loss: 0.2451 | Precision: 0.8030, Recall: 0.6772, F1: 0.7184\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on Test Set: 100%|██████████| 56/56 [00:23<00:00,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Evaluation | Loss: 0.2638 | Precision: 0.8155, Recall: 0.6594, F1: 0.7044\n",
      "\n",
      "Metrics saved to model_evaluation_metrics.csv\n",
      "Average Metrics Over All Folds:\n",
      "precision: 0.8155 (±0.0000)\n",
      "recall: 0.6594 (±0.0000)\n",
      "f1: 0.7044 (±0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# SVM, Random Forest, Gradient Boosting",
   "id": "ccd9856e5cf86718"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T10:08:10.613387Z",
     "start_time": "2024-07-13T10:08:10.600480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_classifier(classifier, X, y):\n",
    "    kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=RANDOM_SEED)\n",
    "    results = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Use a pipeline to handle TF-IDF vectorization and classification\n",
    "        pipeline = make_pipeline(\n",
    "            TfidfVectorizer(max_features=MAX_FEATURES),\n",
    "            OneVsRestClassifier(classifier)\n",
    "        )\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        predictions = pipeline.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        precision = precision_score(y_test, predictions, average='samples')\n",
    "        recall = recall_score(y_test, predictions, average='samples')\n",
    "        f1 = f1_score(y_test, predictions, average='samples')\n",
    "        results.append({'precision': precision, 'recall': recall, 'f1': f1})\n",
    "\n",
    "    return pd.DataFrame(results)"
   ],
   "id": "f5e66a97d61e5925",
   "outputs": [],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T10:09:36.719871Z",
     "start_time": "2024-07-13T10:09:35.972729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = vectorizer.fit_transform(documents)\n",
    "y = labels\n",
    "\n",
    "# Classifier configurations\n",
    "classifiers = {\n",
    "    \"svm\": SVC(kernel='linear', probability=True),\n",
    "    \"random_forest\": RandomForestClassifier(n_estimators=100, random_state=RANDOM_SEED),\n",
    "    \"gradient_boosting\": GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "}\n",
    "\n",
    "for classifier_name, classifier in classifiers.items():\n",
    "    print(f\"\\nTesting classifier: {classifier_name}\")\n",
    "    metrics_df = evaluate_classifier(classifier, x, y)  # Use the full dataset for cross-validation\n",
    "    file_path = os.path.join(LOG_DIR, f\"{classifier_name}_metrics.csv\")\n",
    "    metrics_df.to_csv(file_path, index=False)\n",
    "    print(f\"Saved {classifier_name} cross-validation metrics to {file_path}\")"
   ],
   "id": "cd228b01fa44096f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing classifier: svm\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'csr_matrix' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[111], line 13\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m classifier_name, classifier \u001B[38;5;129;01min\u001B[39;00m classifiers\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mTesting classifier: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mclassifier_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 13\u001B[0m     metrics_df \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_classifier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclassifier\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Use the full dataset for cross-validation\u001B[39;00m\n\u001B[1;32m     14\u001B[0m     file_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(LOG_DIR, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mclassifier_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_metrics.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     15\u001B[0m     metrics_df\u001B[38;5;241m.\u001B[39mto_csv(file_path, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "Cell \u001B[0;32mIn[109], line 13\u001B[0m, in \u001B[0;36mevaluate_classifier\u001B[0;34m(classifier, X, y)\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Use a pipeline to handle TF-IDF vectorization and classification\u001B[39;00m\n\u001B[1;32m      9\u001B[0m pipeline \u001B[38;5;241m=\u001B[39m make_pipeline(\n\u001B[1;32m     10\u001B[0m     TfidfVectorizer(max_features\u001B[38;5;241m=\u001B[39mMAX_FEATURES),\n\u001B[1;32m     11\u001B[0m     OneVsRestClassifier(classifier)\n\u001B[1;32m     12\u001B[0m )\n\u001B[0;32m---> 13\u001B[0m \u001B[43mpipeline\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m predictions \u001B[38;5;241m=\u001B[39m pipeline\u001B[38;5;241m.\u001B[39mpredict(X_test)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# Calculate metrics\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/smart-contracts-vulnerabilities-ml-detector/venv/lib/python3.10/site-packages/sklearn/base.py:1474\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1467\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1469\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1470\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1471\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1472\u001B[0m     )\n\u001B[1;32m   1473\u001B[0m ):\n\u001B[0;32m-> 1474\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/smart-contracts-vulnerabilities-ml-detector/venv/lib/python3.10/site-packages/sklearn/pipeline.py:471\u001B[0m, in \u001B[0;36mPipeline.fit\u001B[0;34m(self, X, y, **params)\u001B[0m\n\u001B[1;32m    428\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Fit the model.\u001B[39;00m\n\u001B[1;32m    429\u001B[0m \n\u001B[1;32m    430\u001B[0m \u001B[38;5;124;03mFit all the transformers one after the other and sequentially transform the\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    468\u001B[0m \u001B[38;5;124;03m    Pipeline with fitted steps.\u001B[39;00m\n\u001B[1;32m    469\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    470\u001B[0m routed_params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_method_params(method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit\u001B[39m\u001B[38;5;124m\"\u001B[39m, props\u001B[38;5;241m=\u001B[39mparams)\n\u001B[0;32m--> 471\u001B[0m Xt \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrouted_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    472\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _print_elapsed_time(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPipeline\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_log_message(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m)):\n\u001B[1;32m    473\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_final_estimator \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpassthrough\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/PycharmProjects/smart-contracts-vulnerabilities-ml-detector/venv/lib/python3.10/site-packages/sklearn/pipeline.py:408\u001B[0m, in \u001B[0;36mPipeline._fit\u001B[0;34m(self, X, y, routed_params)\u001B[0m\n\u001B[1;32m    406\u001B[0m     cloned_transformer \u001B[38;5;241m=\u001B[39m clone(transformer)\n\u001B[1;32m    407\u001B[0m \u001B[38;5;66;03m# Fit or load from cache the current transformer\u001B[39;00m\n\u001B[0;32m--> 408\u001B[0m X, fitted_transformer \u001B[38;5;241m=\u001B[39m \u001B[43mfit_transform_one_cached\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    409\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcloned_transformer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    410\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    411\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    412\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    413\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmessage_clsname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPipeline\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    414\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmessage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_log_message\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep_idx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    415\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrouted_params\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    416\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    417\u001B[0m \u001B[38;5;66;03m# Replace the transformer of the step with the fitted\u001B[39;00m\n\u001B[1;32m    418\u001B[0m \u001B[38;5;66;03m# transformer. This is necessary when loading the transformer\u001B[39;00m\n\u001B[1;32m    419\u001B[0m \u001B[38;5;66;03m# from the cache.\u001B[39;00m\n\u001B[1;32m    420\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps[step_idx] \u001B[38;5;241m=\u001B[39m (name, fitted_transformer)\n",
      "File \u001B[0;32m~/PycharmProjects/smart-contracts-vulnerabilities-ml-detector/venv/lib/python3.10/site-packages/joblib/memory.py:312\u001B[0m, in \u001B[0;36mNotMemorizedFunc.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 312\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/smart-contracts-vulnerabilities-ml-detector/venv/lib/python3.10/site-packages/sklearn/pipeline.py:1303\u001B[0m, in \u001B[0;36m_fit_transform_one\u001B[0;34m(transformer, X, y, weight, message_clsname, message, params)\u001B[0m\n\u001B[1;32m   1301\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _print_elapsed_time(message_clsname, message):\n\u001B[1;32m   1302\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(transformer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit_transform\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 1303\u001B[0m         res \u001B[38;5;241m=\u001B[39m \u001B[43mtransformer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfit_transform\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1304\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1305\u001B[0m         res \u001B[38;5;241m=\u001B[39m transformer\u001B[38;5;241m.\u001B[39mfit(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit\u001B[39m\u001B[38;5;124m\"\u001B[39m, {}))\u001B[38;5;241m.\u001B[39mtransform(\n\u001B[1;32m   1306\u001B[0m             X, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtransform\u001B[39m\u001B[38;5;124m\"\u001B[39m, {})\n\u001B[1;32m   1307\u001B[0m         )\n",
      "File \u001B[0;32m~/PycharmProjects/smart-contracts-vulnerabilities-ml-detector/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:2138\u001B[0m, in \u001B[0;36mTfidfVectorizer.fit_transform\u001B[0;34m(self, raw_documents, y)\u001B[0m\n\u001B[1;32m   2131\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_params()\n\u001B[1;32m   2132\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tfidf \u001B[38;5;241m=\u001B[39m TfidfTransformer(\n\u001B[1;32m   2133\u001B[0m     norm\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm,\n\u001B[1;32m   2134\u001B[0m     use_idf\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_idf,\n\u001B[1;32m   2135\u001B[0m     smooth_idf\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msmooth_idf,\n\u001B[1;32m   2136\u001B[0m     sublinear_tf\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msublinear_tf,\n\u001B[1;32m   2137\u001B[0m )\n\u001B[0;32m-> 2138\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mraw_documents\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2139\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tfidf\u001B[38;5;241m.\u001B[39mfit(X)\n\u001B[1;32m   2140\u001B[0m \u001B[38;5;66;03m# X is already a transformed view of raw_documents so\u001B[39;00m\n\u001B[1;32m   2141\u001B[0m \u001B[38;5;66;03m# we set copy to False\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/smart-contracts-vulnerabilities-ml-detector/venv/lib/python3.10/site-packages/sklearn/base.py:1474\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1467\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1469\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1470\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1471\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1472\u001B[0m     )\n\u001B[1;32m   1473\u001B[0m ):\n\u001B[0;32m-> 1474\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/smart-contracts-vulnerabilities-ml-detector/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1389\u001B[0m, in \u001B[0;36mCountVectorizer.fit_transform\u001B[0;34m(self, raw_documents, y)\u001B[0m\n\u001B[1;32m   1381\u001B[0m             warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m   1382\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUpper case characters found in\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1383\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m vocabulary while \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlowercase\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1384\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m is True. These entries will not\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1385\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m be matched with any documents\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1386\u001B[0m             )\n\u001B[1;32m   1387\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m-> 1389\u001B[0m vocabulary, X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_count_vocab\u001B[49m\u001B[43m(\u001B[49m\u001B[43mraw_documents\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfixed_vocabulary_\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1391\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbinary:\n\u001B[1;32m   1392\u001B[0m     X\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mfill(\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/smart-contracts-vulnerabilities-ml-detector/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1276\u001B[0m, in \u001B[0;36mCountVectorizer._count_vocab\u001B[0;34m(self, raw_documents, fixed_vocab)\u001B[0m\n\u001B[1;32m   1274\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m raw_documents:\n\u001B[1;32m   1275\u001B[0m     feature_counter \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m-> 1276\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m feature \u001B[38;5;129;01min\u001B[39;00m \u001B[43manalyze\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdoc\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m   1277\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1278\u001B[0m             feature_idx \u001B[38;5;241m=\u001B[39m vocabulary[feature]\n",
      "File \u001B[0;32m~/PycharmProjects/smart-contracts-vulnerabilities-ml-detector/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:110\u001B[0m, in \u001B[0;36m_analyze\u001B[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001B[0m\n\u001B[1;32m    108\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    109\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m preprocessor \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 110\u001B[0m         doc \u001B[38;5;241m=\u001B[39m \u001B[43mpreprocessor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdoc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    111\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m tokenizer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    112\u001B[0m         doc \u001B[38;5;241m=\u001B[39m tokenizer(doc)\n",
      "File \u001B[0;32m~/PycharmProjects/smart-contracts-vulnerabilities-ml-detector/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:68\u001B[0m, in \u001B[0;36m_preprocess\u001B[0;34m(doc, accent_function, lower)\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Chain together an optional series of text preprocessing steps to\u001B[39;00m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;124;03mapply to a document.\u001B[39;00m\n\u001B[1;32m     51\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;124;03m    preprocessed string\u001B[39;00m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     67\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m lower:\n\u001B[0;32m---> 68\u001B[0m     doc \u001B[38;5;241m=\u001B[39m \u001B[43mdoc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlower\u001B[49m()\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m accent_function \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     70\u001B[0m     doc \u001B[38;5;241m=\u001B[39m accent_function(doc)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'csr_matrix' object has no attribute 'lower'"
     ]
    }
   ],
   "execution_count": 111
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Simple Neural Network",
   "id": "c489beb8f1bec7f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T08:29:55.377547Z",
     "start_time": "2024-07-13T08:29:55.370505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(MAX_FEATURES, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, y.shape[1])\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x"
   ],
   "id": "efa02ce8766e7c38",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train(model, data_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_predictions, all_labels = [], []\n",
    "    for inputs, labels in data_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Collect predictions for metrics calculation\n",
    "        predicted = outputs.sigmoid().round()\n",
    "        all_predictions.extend(predicted.detach().cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    metrics = compute_metrics(np.array(all_labels), np.array(all_predictions))\n",
    "    return total_loss / len(data_loader), metrics\n",
    "\n",
    "\n",
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    all_predictions, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            predicted = outputs.sigmoid().round()\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    metrics = compute_metrics(np.array(all_labels), np.array(all_predictions))\n",
    "    return metrics"
   ],
   "id": "6d0a8aec50f57280"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T08:29:56.736798Z",
     "start_time": "2024-07-13T08:29:55.379753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.FloatTensor(vectorizer.fit_transform(documents).toarray())\n",
    "y = torch.FloatTensor(labels)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=TEST_SIZE, random_state=RANDOM_SEED)\n",
    "train_data = DataLoader(TensorDataset(x_train, y_train), batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_data = DataLoader(TensorDataset(x_test, y_test), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Model setup\n",
    "model = SimpleNN().to(DEVICE)\n",
    "criterion = nn.BCEWithLogitsLoss().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# K-Fold training and validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(x_train)):\n",
    "    print(f\"Training Fold {fold + 1}/5\")\n",
    "    train_subset = DataLoader(TensorDataset(x_train[train_idx], y_train[train_idx]), batch_size=BATCH_SIZE,\n",
    "                              shuffle=True)\n",
    "    val_subset = DataLoader(TensorDataset(x_train[val_idx], y_train[val_idx]), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_loss, train_metrics = train(model, train_subset, criterion, optimizer, DEVICE)\n",
    "        print(f\"Fold {fold + 1}, Epoch {epoch + 1} - Training Loss: {train_loss:.4f}, Metrics: {train_metrics}\")\n",
    "\n",
    "        val_metrics = evaluate(model, val_subset, DEVICE)\n",
    "        print(f\"Fold {fold + 1}, Epoch {epoch + 1} - Validation Metrics: {val_metrics}\")\n",
    "\n",
    "    # Test evaluation\n",
    "    test_metrics = evaluate(model, test_data, DEVICE)\n",
    "    fold_results.append(test_metrics)\n",
    "    print(f\"Fold {fold + 1} - Test Metrics: {test_metrics}\")\n",
    "\n",
    "# Save all results\n",
    "save_results(fold_results, \"ffnn.csv\")"
   ],
   "id": "a863a02c32516439",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 176/176 [00:00<00:00, 1067.70it/s]\n",
      "Validation: 100%|██████████| 44/44 [00:00<00:00, 10154.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Fold 1, Epoch 1: Accuracy: 0.0909\n",
      "Fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 176/176 [00:00<00:00, 1366.31it/s]\n",
      "Validation: 100%|██████████| 44/44 [00:00<00:00, 11212.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Fold 2, Epoch 1: Accuracy: 0.1705\n",
      "Fold 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 176/176 [00:00<00:00, 1424.92it/s]\n",
      "Validation: 100%|██████████| 44/44 [00:00<00:00, 11707.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Fold 3, Epoch 1: Accuracy: 0.1591\n",
      "Fold 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 176/176 [00:00<00:00, 1450.91it/s]\n",
      "Validation: 100%|██████████| 44/44 [00:00<00:00, 9478.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Fold 4, Epoch 1: Accuracy: 0.1591\n",
      "Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 176/176 [00:00<00:00, 1400.27it/s]\n",
      "Validation: 100%|██████████| 44/44 [00:00<00:00, 11790.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Fold 5, Epoch 1: Accuracy: 0.1477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 56/56 [00:00<00:00, 5144.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation - Accuracy: 0.1171, Precision: 0.8138, Recall: 0.6619, F1:0.7058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# LSTM",
   "id": "990ea60a5cad8c3d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T08:29:56.745068Z",
     "start_time": "2024-07-13T08:29:56.741358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, pretrained_embeddings):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(pretrained_embeddings, dtype=torch.float32))\n",
    "        self.embedding.weight.requires_grad = True  # Optionally freeze the embeddings\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        packed_output, (hidden, cell) = self.lstm(embedded)\n",
    "        hidden = hidden.squeeze(0)\n",
    "        output = self.fc(hidden)\n",
    "        return torch.sigmoid(output)"
   ],
   "id": "e77799d5ed7f928",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train(model, train_data, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_predictions, all_targets = [], []\n",
    "    for inputs, targets in train_data:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # For metrics calculation, we need binary predictions and actual targets\n",
    "        predictions = outputs.sigmoid().round()\n",
    "        all_predictions.extend(predictions.detach().cpu().numpy())\n",
    "        all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(train_data)\n",
    "    training_metrics = compute_metrics(np.vstack(all_targets), np.vstack(all_predictions))\n",
    "    return avg_loss, training_metrics\n",
    "\n",
    "\n",
    "def evaluate(model, data, device):\n",
    "    model.eval()\n",
    "    predictions, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            predictions.extend(outputs.round().detach().cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "    return np.vstack(targets), np.vstack(predictions)\n",
    "\n",
    "\n",
    "# Load GloVe embeddings\n",
    "def load_glove_embeddings(glove_file):\n",
    "    embeddings = {}\n",
    "    with open(glove_file, 'r', encoding='utf-8') as file:\n",
    "        for line in tqdm(file, desc=\"Loading GloVe Embeddings\"):\n",
    "            parts = line.split()\n",
    "            word = parts[0]\n",
    "            vector = np.array(parts[1:], dtype=np.float32)\n",
    "            embeddings[word] = vector\n",
    "    return embeddings"
   ],
   "id": "8fd393ff6e9d3a33"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T08:29:56.867667Z",
     "start_time": "2024-07-13T08:29:56.749403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "glove_embeddings = load_glove_embeddings('glove.6B.100d.txt')  # Update path as necessary\n",
    "\n",
    "# Tokenization and vocabulary creation\n",
    "word_count = Counter(word for sentence in documents for word in sentence.lower().split())\n",
    "vocabulary = {word: i + 1 for i, word in enumerate(word_count)}  # start indexing from 1\n",
    "vocabulary['<PAD>'] = 0  # Padding value\n",
    "\n",
    "# Embedding matrix creation\n",
    "embedding_dim = 100  # Dimensionality of GloVe embeddings used\n",
    "embedding_matrix = np.zeros((len(vocabulary), embedding_dim))\n",
    "for word, i in tqdm(vocabulary.items(), desc='Creating Embedding Matrix'):\n",
    "    embedding_vector = glove_embeddings.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# Convert text to sequence of integers\n",
    "sequences = [[vocabulary[word] for word in text.lower().split()] for text in documents]\n",
    "\n",
    "# Finding the longest sequence\n",
    "max_seq_len = max(len(seq) for seq in sequences)\n",
    "\n",
    "# Pad sequences\n",
    "seq_padded = [seq + [vocabulary['<PAD>']] * (max_seq_len - len(seq)) for seq in sequences]"
   ],
   "id": "a3609dd521dbe50e",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'glove.6B.100d.txt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[63], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m glove_embeddings \u001B[38;5;241m=\u001B[39m \u001B[43mload_glove_embeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mglove.6B.100d.txt\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Update path as necessary\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Tokenization and vocabulary creation\u001B[39;00m\n\u001B[1;32m      4\u001B[0m word_count \u001B[38;5;241m=\u001B[39m Counter(word \u001B[38;5;28;01mfor\u001B[39;00m sentence \u001B[38;5;129;01min\u001B[39;00m documents \u001B[38;5;28;01mfor\u001B[39;00m word \u001B[38;5;129;01min\u001B[39;00m sentence\u001B[38;5;241m.\u001B[39mlower()\u001B[38;5;241m.\u001B[39msplit())\n",
      "Cell \u001B[0;32mIn[62], line 4\u001B[0m, in \u001B[0;36mload_glove_embeddings\u001B[0;34m(glove_file)\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_glove_embeddings\u001B[39m(glove_file):\n\u001B[1;32m      3\u001B[0m     embeddings \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m----> 4\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mglove_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m file:\n\u001B[1;32m      5\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m tqdm(file, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoading GloVe Embeddings\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m      6\u001B[0m             parts \u001B[38;5;241m=\u001B[39m line\u001B[38;5;241m.\u001B[39msplit()\n",
      "File \u001B[0;32m~/PycharmProjects/smart-contracts-vulnerabilities-ml-detector/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001B[0m, in \u001B[0;36m_modified_open\u001B[0;34m(file, *args, **kwargs)\u001B[0m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[1;32m    318\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    319\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    320\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    321\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    322\u001B[0m     )\n\u001B[0;32m--> 324\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'glove.6B.100d.txt'"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x_tensor = torch.tensor(seq_padded, dtype=torch.long)\n",
    "y_tensor = torch.tensor(labels, dtype=torch.float)\n",
    "\n",
    "# Data loading and model setup\n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(x_tensor, y_tensor, test_size=TEST_SIZE,\n",
    "                                                            random_state=RANDOM_SEED)\n",
    "test_data = DataLoader(TensorDataset(x_test, y_test), batch_size=BATCH_SIZE, shuffle=False)\n",
    "kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=RANDOM_SEED)\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(x_train_val)):\n",
    "    print(f\"Training Fold {fold + 1}/5\")\n",
    "    train_data = DataLoader(TensorDataset(x_train_val[train_idx], y_train_val[train_idx]), BATCH_SIZE, shuffle=True)\n",
    "    val_data = DataLoader(TensorDataset(x_train_val[val_idx], y_train_val[val_idx]), BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    model = LSTMClassifier(1000, 50, 100, 1, glove_embeddings)\n",
    "    criterion = nn.BCEWithLogitsLoss().to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_loss, train_metrics = train(model, train_data, criterion, optimizer, DEVICE)\n",
    "        print(f'Fold {fold + 1}, Epoch {epoch + 1} - Training Loss: {train_loss:.4f}, Metrics: {train_metrics}')\n",
    "\n",
    "        val_targets, val_predictions = evaluate(model, val_data, DEVICE)\n",
    "        val_metrics = compute_metrics(val_targets, val_predictions)\n",
    "        print(f'Fold {fold + 1}, Epoch {epoch + 1} - Validation Metrics: {val_metrics}')\n",
    "\n",
    "    test_targets, test_predictions = evaluate(model, test_data, DEVICE)\n",
    "    test_metrics = compute_metrics(test_targets, test_predictions)\n",
    "    fold_results.append(test_metrics)\n",
    "    print(f'Test Set Evaluation - Fold {fold + 1}: {test_metrics}')\n",
    "\n",
    "save_results(fold_results, \"lstm.csv\")"
   ],
   "id": "c00f0ccc3317a45e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
